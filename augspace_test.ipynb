{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Features =  13\n",
      "               0           1           2           3           4           5   \\\n",
      "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
      "mean     0.008522    0.073888    0.020640    0.195830    0.260426    0.539981   \n",
      "std      0.022799    0.124284    0.083151    0.272624    0.192501    0.218922   \n",
      "min      0.000000    0.000160    0.000000    0.000000    0.000000    0.063050   \n",
      "25%      0.000480    0.003652    0.000000    0.000000    0.119593    0.338343   \n",
      "50%      0.001098    0.026668    0.000000    0.000000    0.206012    0.646628   \n",
      "75%      0.003749    0.103316    0.000000    0.330000    0.346041    0.646628   \n",
      "max      0.188890    1.000000    0.850000    0.950000    0.785557    1.000000   \n",
      "\n",
      "               6         7           8           9      ...              18  \\\n",
      "count  500.000000  500.0000  500.000000  500.000000     ...      500.000000   \n",
      "mean     0.014000    0.1420    0.229120    0.502409     ...        0.260664   \n",
      "std      0.117608    0.3494    0.169203    0.235373     ...        0.222169   \n",
      "min      0.000000    0.0000    0.008230    0.051440     ...        0.001908   \n",
      "25%      0.000000    0.0000    0.098765    0.314815     ...        0.146947   \n",
      "50%      0.000000    0.0000    0.207819    0.491770     ...        0.198473   \n",
      "75%      0.000000    0.0000    0.314815    0.674897     ...        0.281011   \n",
      "max      1.000000    1.0000    0.792181    1.000000     ...        0.914122   \n",
      "\n",
      "               19          20          21          22          23          24  \\\n",
      "count  500.000000  500.000000  500.000000  500.000000  500.000000  500.000000   \n",
      "mean     0.603393    0.486043    0.743170    0.830928    0.980942    0.205613   \n",
      "std      0.310402    0.233927    0.160905    0.278812    0.066202    0.127625   \n",
      "min      0.068702    0.000000    0.042553    0.000000    0.152302    0.000000   \n",
      "25%      0.285305    0.276596    0.670213    0.848057    0.985791    0.105615   \n",
      "50%      0.477099    0.510638    0.808511    0.951599    0.996785    0.180188   \n",
      "75%      0.914122    0.691489    0.808511    0.984984    1.000000    0.275041   \n",
      "max      1.000000    0.893617    1.000000    1.000000    1.000000    0.732616   \n",
      "\n",
      "               25          26          27  \n",
      "count  500.000000  500.000000  500.000000  \n",
      "mean     0.412170   27.040229   31.295355  \n",
      "std      0.194956    3.378057    2.861114  \n",
      "min      0.049669   21.387329   22.548652  \n",
      "25%      0.258968   23.851773   29.448104  \n",
      "50%      0.385210   27.076100   32.085501  \n",
      "75%      0.544150   29.489458   33.402600  \n",
      "max      1.000000   34.199699   36.167055  \n",
      "\n",
      "[8 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import RQP_test_data_creator\n",
    "from scipy.io import arff\n",
    "\n",
    "\n",
    "def sample_interval_from_data(data_train):\n",
    "    n = data_train.shape[0]\n",
    "    num_features = data_train.shape[1]\n",
    "    x1 = data_train[np.random.choice(n)]\n",
    "    x2 = data_train[np.random.choice(n)]\n",
    "    feature_intervals = []\n",
    "    for feature in range(num_features):\n",
    "        lower_bound = np.min([x1[feature], x2[feature]])\n",
    "        upper_bound = np.max([x1[feature], x2[feature]])\n",
    "        feature_intervals.append((lower_bound, upper_bound))\n",
    "    return feature_intervals\n",
    "\n",
    "\n",
    "file_path_train = \"RQPdata/boston.arff_RQPtrain.arff\"\n",
    "file_path_test = \"RQPdata/boston.arff_RQPtest.arff\"\n",
    "data_train_raw = pd.DataFrame(arff.loadarff(file_path_train)[0])\n",
    "data_test_raw = pd.DataFrame(arff.loadarff(file_path_test)[0])\n",
    "X_train_raw = data_train_raw.iloc[:, :-1]\n",
    "\n",
    "aug_sample_numbers = [200, 500, 1000, 2000]\n",
    "num_features = X_train_raw.shape[1]\n",
    "print(\"# Features = \", num_features)\n",
    "data_train_aug = []\n",
    "for i in range(aug_sample_numbers[1]):\n",
    "    feature_intervals = sample_interval_from_data(X_train_raw.values)\n",
    "    y_hat_min = np.inf\n",
    "    y_hat_max = -np.inf\n",
    "    for index, data_point in data_train_raw.iterrows():\n",
    "        in_interval = True\n",
    "        for feature in range(num_features):\n",
    "            feature_interval = feature_intervals[feature]\n",
    "            if feature_interval[0] > data_point[feature] or feature_interval[1] < data_point[feature]:\n",
    "                in_interval = False\n",
    "        if in_interval:\n",
    "            y_hat_min = np.min([y_hat_min, data_point[-1]])\n",
    "            y_hat_max = np.max([y_hat_max, data_point[-1]])\n",
    "    #if not y_hat_min == np.inf and not y_hat_max == -np.inf:\n",
    "    aug_point = []\n",
    "    for interval in feature_intervals:\n",
    "        aug_point.append(interval[0])\n",
    "        aug_point.append(interval[1])\n",
    "    aug_point.append(y_hat_min)\n",
    "    aug_point.append(y_hat_max)\n",
    "    data_train_aug.append(aug_point)\n",
    "data_train_aug = pd.DataFrame(data_train_aug)\n",
    "\n",
    "print(data_train_aug.describe())\n",
    "\n",
    "X_test = data_test_raw.iloc[:, :-2]\n",
    "Y_test_min = data_test_raw.iloc[:, -2:]\n",
    "Y_test_max = data_test_raw.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min error: 0.49706278068711424\n",
      "Max error: 0.8105183591813654\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train_aug = data_train_aug.iloc[:, :-2]\n",
    "Y_min_aug = np.ravel(data_train_aug.iloc[:, -2:-1])\n",
    "Y_max_aug = np.ravel(data_train_aug.iloc[:, -1:])\n",
    "\n",
    "min_classifier = RandomForestRegressor()\n",
    "min_classifier = min_classifier.fit(X_train_aug, Y_min_aug)\n",
    "\n",
    "max_classifier = RandomForestRegressor()\n",
    "max_classifier = max_classifier.fit(X_train_aug, Y_max_aug)\n",
    "\n",
    "X_test = data_test_raw.iloc[:, :-2]\n",
    "Y_test_min = data_test_raw.iloc[:, -2:-1]\n",
    "Y_test_max = data_test_raw.iloc[:, -1:]\n",
    "\n",
    "print(\"Min error:\", min_classifier.score(X_test, Y_test_min))\n",
    "print(\"Max error:\", max_classifier.score(X_test, Y_test_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
