{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import RQP_test_data_creator\n",
    "from scipy.io import arff\n",
    "\n",
    "\n",
    "def sample_interval_from_data(data_train):\n",
    "    n = data_train.shape[0]\n",
    "    num_features = data_train.shape[1]\n",
    "    x1 = data_train[np.random.choice(n)]\n",
    "    x2 = data_train[np.random.choice(n)]\n",
    "    feature_intervals = []\n",
    "    for feature in range(num_features):\n",
    "        lower_bound = np.min([x1[feature], x2[feature]])\n",
    "        upper_bound = np.max([x1[feature], x2[feature]])\n",
    "        feature_intervals.append((lower_bound, upper_bound))\n",
    "    return feature_intervals\n",
    "\n",
    "\n",
    "file_path_train = \"RQPdata/boston.arff_RQPtrain.arff\"\n",
    "file_path_test = \"RQPdata/boston.arff_RQPtest.arff\"\n",
    "data_train_raw = pd.DataFrame(arff.loadarff(file_path_train)[0])\n",
    "data_test_raw = pd.DataFrame(arff.loadarff(file_path_test)[0])\n",
    "X_train_raw = data_train_raw.iloc[:, :-1]\n",
    "\n",
    "aug_sample_numbers = [200, 500, 1000, 2000]\n",
    "num_features = X_train_raw.shape[1]\n",
    "data_train_aug = []\n",
    "for i in range(aug_sample_numbers[3]):\n",
    "    feature_intervals = sample_interval_from_data(X_train_raw.values)\n",
    "    y_hat_min = np.inf\n",
    "    y_hat_max = -np.inf\n",
    "    for index, data_point in data_train_raw.iterrows():\n",
    "        in_interval = True\n",
    "        for feature in range(num_features):\n",
    "            feature_interval = feature_intervals[feature]\n",
    "            if feature_interval[0] > data_point[feature] or feature_interval[1] < data_point[feature]:\n",
    "                in_interval = False\n",
    "        if in_interval:\n",
    "            y_hat_min = np.min([y_hat_min, data_point[-1]])\n",
    "            y_hat_max = np.max([y_hat_max, data_point[-1]])\n",
    "    #if not y_hat_min == np.inf and not y_hat_max == -np.inf:\n",
    "    aug_point = []\n",
    "    for interval in feature_intervals:\n",
    "        aug_point.append(interval[0])\n",
    "        aug_point.append(interval[1])\n",
    "    aug_point.append(y_hat_min)\n",
    "    aug_point.append(y_hat_max)\n",
    "    data_train_aug.append(aug_point)\n",
    "data_train_aug = pd.DataFrame(data_train_aug)\n",
    "\n",
    "#print(data_train_aug.describe())\n",
    "\n",
    "X_test = data_test_raw.iloc[:, :-2]\n",
    "Y_test_min = data_test_raw.iloc[:, -2:]\n",
    "Y_test_max = data_test_raw.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min R^2: 0.4109252883285175\n",
      "Max R^2: 0.8159998543560129\n",
      "Min l1: 1.8270046224686112\n",
      "Max l1: 1.1867882911937726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train_aug = data_train_aug.iloc[:, :-2]\n",
    "Y_min_aug = np.ravel(data_train_aug.iloc[:, -2:-1])\n",
    "Y_max_aug = np.ravel(data_train_aug.iloc[:, -1:])\n",
    "\n",
    "reps = 100\n",
    "min_r2s = []\n",
    "max_r2s = []\n",
    "l1_mins = []\n",
    "l1_maxs = []\n",
    "for rep in range(reps):\n",
    "    min_classifier = RandomForestRegressor()\n",
    "    min_classifier = min_classifier.fit(X_train_aug, Y_min_aug)\n",
    "\n",
    "    max_classifier = RandomForestRegressor()\n",
    "    max_classifier = max_classifier.fit(X_train_aug, Y_max_aug)\n",
    "\n",
    "    X_test = data_test_raw.iloc[:, :-2]\n",
    "    Y_test_min = data_test_raw.iloc[:, -2:-1]\n",
    "    Y_test_max = data_test_raw.iloc[:, -1:]\n",
    "\n",
    "    l1_min = np.sum(np.absolute(np.subtract(min_classifier.predict(X_test), np.ravel(Y_test_min)))) / X_test.shape[0]\n",
    "    l1_max = np.sum(np.absolute(np.subtract(max_classifier.predict(X_test), np.ravel(Y_test_max)))) / X_test.shape[0]\n",
    "    \n",
    "    min_r2s.append(min_classifier.score(X_test, Y_test_min))\n",
    "    max_r2s.append(max_classifier.score(X_test, Y_test_max))\n",
    "    l1_mins.append(l1_min)\n",
    "    l1_maxs.append(l1_max)\n",
    "    \n",
    "print(\"Min R^2:\", np.mean(min_r2s))\n",
    "print(\"Max R^2:\", np.mean(max_r2s))\n",
    "print(\"Min l1:\", np.mean(l1_mins))\n",
    "print(\"Max l1:\", np.mean(l1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import RQP_test_data_creator\n",
    "from scipy.io import arff\n",
    "\n",
    "\n",
    "def sample_interval_from_data(data_train):\n",
    "    n = data_train.shape[0]\n",
    "    num_features = data_train.shape[1]\n",
    "    x1 = data_train[np.random.choice(n)]\n",
    "    x2 = data_train[np.random.choice(n)]\n",
    "    feature_intervals = []\n",
    "    for feature in range(num_features):\n",
    "        lower_bound = np.min([x1[feature], x2[feature]])\n",
    "        upper_bound = np.max([x1[feature], x2[feature]])\n",
    "        feature_intervals.append((lower_bound, upper_bound))\n",
    "    return feature_intervals\n",
    "\n",
    "\n",
    "file_path_train = \"RQPdata/cpu.small.arff_RQPtrain.arff\"\n",
    "file_path_test = \"RQPdata/cpu.small.arff_RQPtest.arff\"\n",
    "data_train_raw = pd.DataFrame(arff.loadarff(file_path_train)[0])\n",
    "data_test_raw = pd.DataFrame(arff.loadarff(file_path_test)[0])\n",
    "X_train_raw = data_train_raw.iloc[:, :-1]\n",
    "\n",
    "#aug_sample_numbers = [200, 500, 1000, 2000]\n",
    "num_features = X_train_raw.shape[1]\n",
    "data_train_aug = []\n",
    "for i in range(8000):\n",
    "    feature_intervals = sample_interval_from_data(X_train_raw.values)\n",
    "    y_hat_min = np.inf\n",
    "    y_hat_max = -np.inf\n",
    "    for index, data_point in data_train_raw.iterrows():\n",
    "        in_interval = True\n",
    "        for feature in range(num_features):\n",
    "            feature_interval = feature_intervals[feature]\n",
    "            if feature_interval[0] > data_point[feature] or feature_interval[1] < data_point[feature]:\n",
    "                in_interval = False\n",
    "        if in_interval:\n",
    "            y_hat_min = np.min([y_hat_min, data_point[-1]])\n",
    "            y_hat_max = np.max([y_hat_max, data_point[-1]])\n",
    "    #if not y_hat_min == np.inf and not y_hat_max == -np.inf:\n",
    "    aug_point = []\n",
    "    for interval in feature_intervals:\n",
    "        aug_point.append(interval[0])\n",
    "        aug_point.append(interval[1])\n",
    "    aug_point.append(y_hat_min)\n",
    "    aug_point.append(y_hat_max)\n",
    "    data_train_aug.append(aug_point)\n",
    "data_train_aug = pd.DataFrame(data_train_aug)\n",
    "\n",
    "#print(data_train_aug.describe())\n",
    "\n",
    "X_test = data_test_raw.iloc[:, :-2]\n",
    "Y_test_min = data_test_raw.iloc[:, -2:]\n",
    "Y_test_max = data_test_raw.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min R^2: 0.6191485325068501\n",
      "Max R^2: 0.75157965172968\n",
      "Min l1: 0.04640308741278421\n",
      "Max l1: 0.04534470975012554\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train_aug = data_train_aug.iloc[:, :-2]\n",
    "Y_min_aug = np.ravel(data_train_aug.iloc[:, -2:-1])\n",
    "Y_max_aug = np.ravel(data_train_aug.iloc[:, -1:])\n",
    "\n",
    "reps = 100\n",
    "min_r2s = []\n",
    "max_r2s = []\n",
    "l1_mins = []\n",
    "l1_maxs = []\n",
    "for rep in range(reps):\n",
    "    min_classifier = RandomForestRegressor()\n",
    "    min_classifier = min_classifier.fit(X_train_aug, Y_min_aug)\n",
    "\n",
    "    max_classifier = RandomForestRegressor()\n",
    "    max_classifier = max_classifier.fit(X_train_aug, Y_max_aug)\n",
    "\n",
    "    X_test = data_test_raw.iloc[:, :-2]\n",
    "    Y_test_min = data_test_raw.iloc[:, -2:-1]\n",
    "    Y_test_max = data_test_raw.iloc[:, -1:]\n",
    "\n",
    "    l1_min = np.sum(np.absolute(np.subtract(min_classifier.predict(X_test), np.ravel(Y_test_min)))) / X_test.shape[0]\n",
    "    l1_max = np.sum(np.absolute(np.subtract(max_classifier.predict(X_test), np.ravel(Y_test_max)))) / X_test.shape[0]\n",
    "    \n",
    "    min_r2s.append(min_classifier.score(X_test, Y_test_min))\n",
    "    max_r2s.append(max_classifier.score(X_test, Y_test_max))\n",
    "    l1_mins.append(l1_min)\n",
    "    l1_maxs.append(l1_max)\n",
    "    \n",
    "print(\"Min R^2:\", np.mean(min_r2s))\n",
    "print(\"Max R^2:\", np.mean(max_r2s))\n",
    "print(\"Min l1:\", np.mean(l1_mins))\n",
    "print(\"Max l1:\", np.mean(l1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
